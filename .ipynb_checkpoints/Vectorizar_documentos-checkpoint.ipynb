{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info de: https://unipython.com/como-preparar-datos-de-texto-con-scikit-learn/\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import json\n",
    "import numpy\n",
    "import re, string\n",
    "#Para guardar matriz de vectores\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I open json file with dataset, whose structure is:\n",
    "#category\n",
    "#headline\n",
    "#authors\n",
    "#link\n",
    "#short_description\n",
    "#date\n",
    "with open(r'C:\\Users\\maricel\\Documents\\AYELEN\\Investigacion\\News_Category_Dataset_v2.json') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de noticias:  200853\n"
     ]
    }
   ],
   "source": [
    "#I'll take the short description of each news\n",
    "short_data = [desc['short_description'] for desc in data]\n",
    "print('cantidad de noticias: ', len(short_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I take the words from each description and create a vocabulary of all the unique words in the descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(short_data)\n",
    "vocabulario = vectorizer.vocabulary_\n",
    "#print(vocabulario)\n",
    "#print(len(vocabulario)) = 74035\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I generate vectors of the size of the vocabulary for each short_description where in the position that indicates the\n",
    "#vocabulary for that word, it places its occurrence in the description.\n",
    "palabras_vectorizadas = vectorizer.transform(short_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200853, 74035)\n",
      "  (0, 3439)\t1\n",
      "  (0, 3909)\t1\n",
      "  (0, 12494)\t1\n",
      "  (0, 17023)\t1\n",
      "  (0, 29823)\t1\n",
      "  (0, 30273)\t1\n",
      "  (0, 31755)\t1\n",
      "  (0, 32594)\t1\n",
      "  (0, 35333)\t1\n",
      "  (0, 36214)\t1\n",
      "  (0, 37900)\t1\n",
      "  (0, 59400)\t1\n",
      "  (0, 66005)\t1\n",
      "  (1, 15519)\t1\n",
      "  (1, 29626)\t1\n",
      "  (1, 34198)\t1\n",
      "  (1, 46622)\t1\n",
      "  (1, 61534)\t1\n",
      "  (2, 2025)\t1\n",
      "  (2, 3663)\t1\n",
      "  (2, 3838)\t1\n",
      "  (2, 11839)\t1\n",
      "  (2, 12996)\t1\n",
      "  (2, 20802)\t1\n",
      "  (2, 27278)\t1\n",
      "  :\t:\n",
      "  (200851, 63234)\t1\n",
      "  (200851, 65973)\t2\n",
      "  (200851, 66175)\t1\n",
      "  (200851, 70374)\t1\n",
      "  (200852, 591)\t1\n",
      "  (200852, 2502)\t1\n",
      "  (200852, 3084)\t1\n",
      "  (200852, 11782)\t1\n",
      "  (200852, 14016)\t1\n",
      "  (200852, 21661)\t1\n",
      "  (200852, 24597)\t1\n",
      "  (200852, 25825)\t1\n",
      "  (200852, 30687)\t1\n",
      "  (200852, 33733)\t1\n",
      "  (200852, 39216)\t1\n",
      "  (200852, 45525)\t1\n",
      "  (200852, 47295)\t1\n",
      "  (200852, 56695)\t1\n",
      "  (200852, 62640)\t1\n",
      "  (200852, 65424)\t1\n",
      "  (200852, 65973)\t1\n",
      "  (200852, 66523)\t1\n",
      "  (200852, 66699)\t1\n",
      "  (200852, 66966)\t1\n",
      "  (200852, 68147)\t1\n"
     ]
    }
   ],
   "source": [
    "print(palabras_vectorizadas.shape)\n",
    "print(palabras_vectorizadas)\n",
    "# print(palabras_vectorizadas.toarray()) #to visualize it in matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I save the dictionary in a JSON file\n",
    "with open('diccionario_string.json', 'w') as file:\n",
    "    json.dump(str(vocabulario), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I save the vector matrix\n",
    "matriz = palabras_vectorizadas#.toarray()\n",
    "scipy.sparse.save_npz('matriz_palabras_vectorizadas.npz',matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To call the saved matrix\n",
    "#sparse_matrix = scipy.sparse.load_npz('matriz_palabras_vectorizadas.npz') #to import\n",
    "#print(sparse_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
